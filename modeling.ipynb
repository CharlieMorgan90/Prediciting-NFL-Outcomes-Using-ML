{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e33261c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy for FeildGoalStatsSpecialTeams.csv: 0.57 Standard Deviation:  0.05\n",
      "Average Accuracy for PassingStatsDefense.csv: 0.56 Standard Deviation:  0.05\n",
      "Average Accuracy for RushingStatsDefense.csv: 0.59 Standard Deviation:  0.05\n",
      "Average Accuracy for RecievingStatsDefense.csv: 0.59 Standard Deviation:  0.05\n",
      "Average Accuracy for PassingStatsOffense.csv: 0.60 Standard Deviation:  0.04\n",
      "Average Accuracy for InterceptionStatsDefense.csv: 0.56 Standard Deviation:  0.05\n",
      "Average Accuracy for KickoffReturnsStatsSpecialTeams.csv: 0.51 Standard Deviation:  0.05\n",
      "Average Accuracy for PuntReturnsStatsSpecialTeams.csv: 0.54 Standard Deviation:  0.05\n",
      "Average Accuracy for RushingStatsOffense.csv: 0.56 Standard Deviation:  0.05\n",
      "Average Accuracy for RecievingStatsOffense.csv: 0.60 Standard Deviation:  0.05\n",
      "Average Accuracy for PuntingStatsSpecialTeams.csv: 0.56 Standard Deviation:  0.05\n",
      "Average Accuracy for KickoffsSpecialTeams.csv: 0.59 Standard Deviation:  0.05\n",
      "Average Accuracy for ScoringStatsSpecialTeams.csv: 0.56 Standard Deviation:  0.05\n",
      "Average Accuracy for DownsStatsOffense.csv: 0.60 Standard Deviation:  0.05\n",
      "Average Accuracy for ScoringStatsOffense.csv: 0.62 Standard Deviation:  0.06\n",
      "Average Accuracy for FumbleStatsDefense.csv: 0.58 Standard Deviation:  0.05\n",
      "Average Accuracy for DownsStatsDefense.csv: 0.55 Standard Deviation:  0.05\n",
      "Average Accuracy for TackleStatsDefense.csv: 0.54 Standard Deviation:  0.05\n",
      "Average Accuracy for ScoringStatsDefense.csv: 0.56 Standard Deviation:  0.05\n",
      "Average Accuracy for offense_merged_stats.csv: 0.62 Standard Deviation:  0.05\n",
      "Average Accuracy for defense_merged_stats.csv: 0.58 Standard Deviation:  0.04\n",
      "Average Accuracy for specialteams_merged_stats.csv: 0.57 Standard Deviation:  0.06\n",
      "Average Accuracy for combined_all_stats.csv: 0.58 Standard Deviation:  0.05\n"
     ]
    }
   ],
   "source": [
    "#Running all files through a randomforest model multiple times to find the mean accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "file_names = [\n",
    "    'FeildGoalStatsSpecialTeams.csv', 'PassingStatsDefense.csv', 'RushingStatsDefense.csv', \n",
    "    'RecievingStatsDefense.csv', 'PassingStatsOffense.csv', 'InterceptionStatsDefense.csv',\n",
    "    'KickoffReturnsStatsSpecialTeams.csv', 'PuntReturnsStatsSpecialTeams.csv',\n",
    "    'RushingStatsOffense.csv', 'RecievingStatsOffense.csv',\n",
    "    'PuntingStatsSpecialTeams.csv', 'KickoffsSpecialTeams.csv', \n",
    "    'ScoringStatsSpecialTeams.csv', 'DownsStatsOffense.csv', 'ScoringStatsOffense.csv',\n",
    "    'FumbleStatsDefense.csv', 'DownsStatsDefense.csv', 'TackleStatsDefense.csv',\n",
    "    'ScoringStatsDefense.csv', 'offense_merged_stats.csv', 'defense_merged_stats.csv', \n",
    "    'specialteams_merged_stats.csv', 'combined_all_stats.csv']\n",
    "\n",
    "input_base_path = '/Users/charlesmorgan/Desktop/Merged Data/'\n",
    "\n",
    "for file in file_names:\n",
    "    stats_filepath = os.path.join(input_base_path, file)\n",
    "    merged_data = pd.read_csv(stats_filepath)\n",
    "\n",
    "    columns_to_drop = ['Week', 'Away Team', 'Home Team', 'Winning Team']\n",
    "    merged_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    X = merged_data.drop('Home_Win', axis=1)\n",
    "    y = merged_data['Home_Win']\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for _ in range(40):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=None)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    average_accuracy = np.mean(accuracies)\n",
    "    std_deviation = np.std(accuracies)\n",
    "\n",
    "    print(f'Average Accuracy for {file}: {average_accuracy:.2f} Standard Deviation:  {std_deviation:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "febe1e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7299698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Results for offense_merged_stats.csv:\n",
      "\n",
      "SVM Accuracy: 0.6617647058823529\n",
      "Logistic Regression Accuracy: 0.6617647058823529\n",
      "Random Forest Accuracy: 0.6911764705882353\n",
      "Gradient Boosting Accuracy: 0.6911764705882353\n",
      "Neural Network Accuracy: 0.6617647058823529\n",
      "\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Results for defense_merged_stats.csv:\n",
      "\n",
      "SVM Accuracy: 0.6764705882352942\n",
      "Logistic Regression Accuracy: 0.6764705882352942\n",
      "Random Forest Accuracy: 0.6764705882352942\n",
      "Gradient Boosting Accuracy: 0.6617647058823529\n",
      "Neural Network Accuracy: 0.7205882352941176\n",
      "\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Results for specialteams_merged_stats.csv:\n",
      "\n",
      "SVM Accuracy: 0.6617647058823529\n",
      "Logistic Regression Accuracy: 0.6176470588235294\n",
      "Random Forest Accuracy: 0.6617647058823529\n",
      "Gradient Boosting Accuracy: 0.6323529411764706\n",
      "Neural Network Accuracy: 0.6029411764705882\n",
      "\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Results for combined_all_stats.csv:\n",
      "\n",
      "SVM Accuracy: 0.6617647058823529\n",
      "Logistic Regression Accuracy: 0.6323529411764706\n",
      "Random Forest Accuracy: 0.7058823529411765\n",
      "Gradient Boosting Accuracy: 0.6470588235294118\n",
      "Neural Network Accuracy: 0.6911764705882353\n",
      "\n",
      "\n",
      "Top 3 Features:\n",
      "SVM:\n",
      "offense_ru_Lng_away           0.134167\n",
      "specialteams_pu_Lng_y_home    0.126884\n",
      "defense_ru_20_home            0.115877\n",
      "dtype: float64\n",
      "Logistic Regression:\n",
      "specialteams_fe_60+ > A-M_away    0.284462\n",
      "specialteams_pu_P Blk_y_home      0.244785\n",
      "specialteams_ki_FG Blk_home       0.213756\n",
      "dtype: float64\n",
      "Random Forest:\n",
      "specialteams_ki_KO_home       0.010610\n",
      "defense_ru_Att_home           0.009325\n",
      "specialteams_ki_Yds_y_home    0.008343\n",
      "dtype: float64\n",
      "Gradient Boosting:\n",
      "offense_sc_Tot TD_home     0.035924\n",
      "defense_ru_Att_away        0.033071\n",
      "specialteams_ki_KO_home    0.030278\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Running combined files through multiple different ml algs to find the optimal one. Finding the optimal features\n",
    "#used in each model.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def analyze_dataset(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    columns_to_drop = ['Week', 'Away Team', 'Home Team', 'Winning Team']\n",
    "    X = data.drop(columns_to_drop + ['Home_Win'], axis=1)\n",
    "    y = data['Home_Win']\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "    #scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    #SVM\n",
    "    svm_model = SVC(kernel='linear')\n",
    "    svm_model.fit(X_train_scaled, y_train)\n",
    "    svm_predictions = svm_model.predict(X_test_scaled)\n",
    "    \n",
    "    #Log\n",
    "    logistic_model = LogisticRegression()\n",
    "    logistic_model.fit(X_train_scaled, y_train)\n",
    "    logistic_predictions = logistic_model.predict(X_test_scaled)\n",
    "    \n",
    "    #Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_predictions = rf_model.predict(X_test)\n",
    "    \n",
    "    #Gradient Boosting\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    gb_predictions = gb_model.predict(X_test)\n",
    "    \n",
    "    #S Neural Network\n",
    "    nn_model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    nn_model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "    nn_probabilities = nn_model.predict(X_test_scaled)\n",
    "    nn_predictions = (nn_probabilities > 0.5).astype(int)\n",
    "    \n",
    "    print(f\"Results for {data_path.split('/')[-1]}:\")\n",
    "    print('')\n",
    "    print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "    print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logistic_predictions))\n",
    "    print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "    print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb_predictions))\n",
    "    print(\"Neural Network Accuracy:\", accuracy_score(y_test, nn_predictions))\n",
    "    print('')\n",
    "    #print(\"\\nClassification Reports:\")\n",
    "    #print(\"Random Forest Classification Report:\")\n",
    "    #print(classification_report(y_test, rf_predictions))\n",
    "    #print(\"Gradient Boosting Classification Report:\")\n",
    "    #print(classification_report(y_test, gb_predictions))\n",
    "    \n",
    "    if data_path == '/Users/charlesmorgan/Desktop/Merged Data/combined_all_stats.csv':\n",
    "        print(\"\\nTop 3 Features:\")\n",
    "\n",
    "        if hasattr(svm_model, 'coef_'):\n",
    "            svm_importances = pd.Series(abs(svm_model.coef_[0]), index=X.columns).sort_values(ascending=False)\n",
    "            print(\"SVM:\")\n",
    "            print(svm_importances.head(3))\n",
    "\n",
    "        if hasattr(logistic_model, 'coef_'):\n",
    "            logistic_importances = pd.Series(abs(logistic_model.coef_[0]), index=X.columns).sort_values(ascending=False)\n",
    "            print(\"Logistic Regression:\")\n",
    "            print(logistic_importances.head(3))\n",
    "\n",
    "        rf_feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(\"Random Forest:\")\n",
    "        print(rf_feature_importances.head(3))\n",
    "\n",
    "        gb_feature_importances = pd.Series(gb_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(\"Gradient Boosting:\")\n",
    "        print(gb_feature_importances.head(3))\n",
    "\n",
    "\n",
    "datasets = [\n",
    "    '/Users/charlesmorgan/Desktop/Merged Data/offense_merged_stats.csv',\n",
    "    '/Users/charlesmorgan/Desktop/Merged Data/defense_merged_stats.csv',\n",
    "    '/Users/charlesmorgan/Desktop/Merged Data/specialteams_merged_stats.csv',\n",
    "    '/Users/charlesmorgan/Desktop/Merged Data/combined_all_stats.csv'\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    analyze_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22bf11c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 216 candidates, totalling 1512 fits\n",
      "\n",
      "Top 10 Features by Importance:\n",
      "                              Feature  Importance\n",
      "155           specialteams_ki_KO_home    0.017782\n",
      "219               defense_pa_Att_away    0.015135\n",
      "114  specialteams_fe_40-49 > A-M_home    0.012335\n",
      "130        specialteams_pu_Avg_x_home    0.010375\n",
      "272               defense_ta_Sck_away    0.009844\n",
      "87                 defense_fu_FF_home    0.009748\n",
      "37            offense_do_4th Att_home    0.009676\n",
      "28                 offense_re_TD_home    0.009488\n",
      "200                offense_re_20_away    0.009299\n",
      "314        specialteams_pu_Avg_y_away    0.008974\n",
      "\n",
      "Best model parameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Test Accuracy: 0.6911764705882353\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63        30\n",
      "           1       0.71      0.76      0.73        38\n",
      "\n",
      "    accuracy                           0.69        68\n",
      "   macro avg       0.69      0.68      0.68        68\n",
      "weighted avg       0.69      0.69      0.69        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Attempting a grid search to find optimal parameters\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "data_path = '/Users/charlesmorgan/Desktop/Merged Data/combined_all_stats.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "columns_to_drop = ['Week', 'Away Team', 'Home Team', 'Winning Team']\n",
    "\n",
    "X = data.drop(columns_to_drop + ['Home_Win'], axis=1)\n",
    "y = data['Home_Win']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "#GridSearch\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 75, 100, 125],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=7, verbose=1, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "feature_importances = best_rf.feature_importances_\n",
    "features = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "print(\"\\nTop 10 Features by Importance:\")\n",
    "print(features.head(10))\n",
    "print()\n",
    "\n",
    "predictions = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Best model parameters:\", grid_search.best_params_)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4bef161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Random Forest Accuracy: 0.71\n",
      "\n",
      "Top 10 Features:\n",
      "                        Feature  Importance\n",
      "155     specialteams_ki_KO_home    0.010610\n",
      "62          defense_ru_Att_home    0.009325\n",
      "156  specialteams_ki_Yds_y_home    0.008343\n",
      "219         defense_pa_Att_away    0.008120\n",
      "13          offense_pa_Sck_home    0.007388\n",
      "37      offense_do_4th Att_home    0.007249\n",
      "36       offense_do_3rd Md_home    0.006739\n",
      "46       offense_sc_Tot TD_home    0.006732\n",
      "9          offense_pa_1st%_home    0.006721\n",
      "39      offense_do_Rec 1st_home    0.006434\n",
      "\n",
      "Improved Random Forest Accuracy with top 190 features: 0.75 Std Dev: 0.00\n",
      "\n",
      "Random Forest Classification Report with Important Features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71        30\n",
      "           1       0.77      0.79      0.78        38\n",
      "\n",
      "    accuracy                           0.75        68\n",
      "   macro avg       0.75      0.74      0.75        68\n",
      "weighted avg       0.75      0.75      0.75        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Eliminate unimportant features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def analyze_dataset(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    columns_to_drop = ['Week', 'Away Team', 'Home Team', 'Winning Team']\n",
    "    \n",
    "    X = data.drop(columns_to_drop + ['Home_Win'], axis=1)\n",
    "    y = data['Home_Win']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    '''\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=50,         \n",
    "        max_depth=None,           \n",
    "        max_features='auto',      \n",
    "        min_samples_leaf=4,       \n",
    "        min_samples_split=10,      \n",
    "        random_state=42           \n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    initial_predictions = rf_model.predict(X_test)\n",
    "    initial_accuracy = accuracy_score(y_test, initial_predictions)\n",
    "    print(f\"Initial Random Forest Accuracy: {initial_accuracy:.2f}\")\n",
    "\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "    features = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(\"\\nTop 10 Features:\")\n",
    "    print(features.head(10))\n",
    "    print('')\n",
    "    \n",
    "    important_accuracies = []\n",
    "\n",
    "    for x in range(20):\n",
    "        n = 190 \n",
    "        important_features = features.head(n)['Feature']\n",
    "\n",
    "        X_train_important = X_train[important_features]\n",
    "        X_test_important = X_test[important_features]\n",
    "\n",
    "        rf_model.fit(X_train_important, y_train)\n",
    "        important_predictions = rf_model.predict(X_test_important)\n",
    "        important_accuracy = accuracy_score(y_test, important_predictions)\n",
    "        important_accuracies.append(important_accuracy)\n",
    "\n",
    "    average_accuracy = np.mean(important_accuracies)\n",
    "    std_deviation = np.std(important_accuracies)\n",
    "\n",
    "    print(f\"Improved Random Forest Accuracy with top {n} features: {average_accuracy:.2f} Std Dev: {std_deviation:.2f}\")\n",
    "    print('')\n",
    "    print(\"Random Forest Classification Report with Important Features:\")\n",
    "    print(classification_report(y_test, important_predictions))\n",
    "    \n",
    "datasets = [\n",
    "    '/Users/charlesmorgan/Desktop/Merged Data/combined_all_stats.csv'\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    analyze_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34dbd71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 0.61 ± 0.04\n",
      "\n",
      "Top 10 Features:\n",
      "                        Feature  Importance\n",
      "233         defense_ru_Att_away    0.012323\n",
      "178        offense_pa_Rate_away    0.008906\n",
      "155     specialteams_ki_KO_home    0.008879\n",
      "327  specialteams_ki_Yds_y_away    0.008686\n",
      "37      offense_do_4th Att_home    0.007656\n",
      "45       offense_sc_Rec TD_home    0.007420\n",
      "326     specialteams_ki_KO_away    0.007368\n",
      "40     offense_do_Rec 1st%_home    0.006902\n",
      "219         defense_pa_Att_away    0.006835\n",
      "197         offense_re_Yds_away    0.006669\n",
      "\n",
      "Cross-Validation Accuracy with Top 100 Features: 0.64 ± 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cross validation to show how well it would actually perform on outside data.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def analyze_dataset(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    columns_to_drop = ['Week', 'Away Team', 'Home Team', 'Winning Team']\n",
    "    X = data.drop(columns_to_drop + ['Home_Win'], axis=1)\n",
    "    y = data['Home_Win']\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cross_val_scores = cross_val_score(rf_model, X, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"Cross-Validation Accuracy: {np.mean(cross_val_scores):.2f} ± {np.std(cross_val_scores):.2f}\")\n",
    "    \n",
    "    rf_model.fit(X, y)\n",
    "    feature_importances = rf_model.feature_importances_\n",
    "    features = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features:\")\n",
    "    print(features.head(10))\n",
    "    print('')\n",
    "    \n",
    "    n = 100 \n",
    "    important_features = features.head(n)['Feature']\n",
    "    \n",
    "    X_important = X[important_features]\n",
    "    cross_val_scores_important = cross_val_score(rf_model, X_important, y, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    print(f\"Cross-Validation Accuracy with Top {n} Features: {np.mean(cross_val_scores_important):.2f} ± {np.std(cross_val_scores_important):.2f}\")\n",
    "    print('')\n",
    "\n",
    "datasets = [\n",
    "    '/Users/charlesmorgan/Desktop/Merged Data/combined_all_stats.csv'\n",
    "]\n",
    "\n",
    "for dataset in datasets:\n",
    "    analyze_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058850c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
